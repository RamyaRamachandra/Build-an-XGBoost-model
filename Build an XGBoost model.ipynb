{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Build an XGBoost model<a href=\"#Activity:-Build-an-XGBoost-model\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "## Introduction<a href=\"#Introduction\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In this activity, you’ll build on the skills and techniques you learned\n",
    "in the decision tree and random forest lessons to construct your own\n",
    "XGBoost classification model. The XGBoost model is a very powerful\n",
    "extension of decision trees, so having a strong working familiarity with\n",
    "this process will strengthen your skills and resume as a data\n",
    "professional.\n",
    "\n",
    "This activity is a continuation of the airlines project in which you\n",
    "built decision tree and random forest models. You will use the same\n",
    "data, but this time you will train, tune, and evaluate an XGBoost model.\n",
    "You’ll then compare the performance of all three models and decide which\n",
    "model is best. Finally, you’ll explore the feature importances of your\n",
    "model and identify the features that most contribute to customer\n",
    "satisfaction.\n",
    "\n",
    "## Step 1: Imports<a href=\"#Step-1:-Imports\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Import packages<a href=\"#Import-packages\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Begin with your import statements. First, import `pandas`, `numpy`, and\n",
    "`matplotlib` for data preparation. Next, import scikit-learn (`sklearn`)\n",
    "for model preparation and evaluation. Then, import `xgboost`, which\n",
    "provides the classification algorithm you'll implement to formulate your\n",
    "predictive model.\n",
    "\n",
    "In \\[1\\]:\n",
    "\n",
    "    # Import relevant libraries and modules.\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib as plt\n",
    "    import pickle\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn import metrics\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    from xgboost import plot_importance\n",
    "\n",
    "### Load the dataset<a href=\"#Load-the-dataset\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "To formulate your model, `pandas` is used to import a csv of airline\n",
    "passenger satisfaction data called `Invistico_Airline.csv`. This\n",
    "DataFrame is called `airline_data`. As shown in this cell, the dataset\n",
    "has been automatically loaded in for you. You do not need to download\n",
    "the .csv file, or provide more code, in order to access the dataset and\n",
    "proceed with this lab. Please continue with this activity by completing\n",
    "the following instructions.\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "    # RUN THIS CELL TO IMPORT YOUR DATA. \n",
    "    airline_data = pd.read_csv('Invistico_Airline.csv', error_bad_lines=False)\n",
    "\n",
    "### Display the data<a href=\"#Display-the-data\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Examine the first 10 rows of data to familiarize yourself with the\n",
    "dataset.\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    # Display the first ten rows of data.\n",
    "    airline_data.head(10)\n",
    "\n",
    "Out\\[3\\]:\n",
    "\n",
    "|     | satisfaction | Customer Type  | Age | Type of Travel  | Class    | Flight Distance | Seat comfort | Departure/Arrival time convenient | Food and drink | Gate location | ... | Online support | Ease of Online booking | On-board service | Leg room service | Baggage handling | Checkin service | Cleanliness | Online boarding | Departure Delay in Minutes | Arrival Delay in Minutes |\n",
    "|-----|--------------|----------------|-----|-----------------|----------|-----------------|--------------|-----------------------------------|----------------|---------------|-----|----------------|------------------------|------------------|------------------|------------------|-----------------|-------------|-----------------|----------------------------|--------------------------|\n",
    "| 0   | satisfied    | Loyal Customer | 65  | Personal Travel | Eco      | 265             | 0            | 0                                 | 0              | 2             | ... | 2              | 3                      | 3                | 0                | 3                | 5               | 3           | 2               | 0                          | 0.0                      |\n",
    "| 1   | satisfied    | Loyal Customer | 47  | Personal Travel | Business | 2464            | 0            | 0                                 | 0              | 3             | ... | 2              | 3                      | 4                | 4                | 4                | 2               | 3           | 2               | 310                        | 305.0                    |\n",
    "| 2   | satisfied    | Loyal Customer | 15  | Personal Travel | Eco      | 2138            | 0            | 0                                 | 0              | 3             | ... | 2              | 2                      | 3                | 3                | 4                | 4               | 4           | 2               | 0                          | 0.0                      |\n",
    "| 3   | satisfied    | Loyal Customer | 60  | Personal Travel | Eco      | 623             | 0            | 0                                 | 0              | 3             | ... | 3              | 1                      | 1                | 0                | 1                | 4               | 1           | 3               | 0                          | 0.0                      |\n",
    "| 4   | satisfied    | Loyal Customer | 70  | Personal Travel | Eco      | 354             | 0            | 0                                 | 0              | 3             | ... | 4              | 2                      | 2                | 0                | 2                | 4               | 2           | 5               | 0                          | 0.0                      |\n",
    "| 5   | satisfied    | Loyal Customer | 30  | Personal Travel | Eco      | 1894            | 0            | 0                                 | 0              | 3             | ... | 2              | 2                      | 5                | 4                | 5                | 5               | 4           | 2               | 0                          | 0.0                      |\n",
    "| 6   | satisfied    | Loyal Customer | 66  | Personal Travel | Eco      | 227             | 0            | 0                                 | 0              | 3             | ... | 5              | 5                      | 5                | 0                | 5                | 5               | 5           | 3               | 17                         | 15.0                     |\n",
    "| 7   | satisfied    | Loyal Customer | 10  | Personal Travel | Eco      | 1812            | 0            | 0                                 | 0              | 3             | ... | 2              | 2                      | 3                | 3                | 4                | 5               | 4           | 2               | 0                          | 0.0                      |\n",
    "| 8   | satisfied    | Loyal Customer | 56  | Personal Travel | Business | 73              | 0            | 0                                 | 0              | 3             | ... | 5              | 4                      | 4                | 0                | 1                | 5               | 4           | 4               | 0                          | 0.0                      |\n",
    "| 9   | satisfied    | Loyal Customer | 22  | Personal Travel | Eco      | 1556            | 0            | 0                                 | 0              | 3             | ... | 2              | 2                      | 2                | 4                | 5                | 3               | 4           | 2               | 30                         | 26.0                     |\n",
    "\n",
    "10 rows × 22 columns\n",
    "\n",
    "### Display the data type for each column<a href=\"#Display-the-data-type-for-each-column\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Next, observe the types of data present within this dataset.\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "    # Display the data type for each column in your DataFrame.\n",
    "    airline_data.dtypes\n",
    "\n",
    "Out\\[4\\]:\n",
    "\n",
    "    satisfaction                          object\n",
    "    Customer Type                         object\n",
    "    Age                                    int64\n",
    "    Type of Travel                        object\n",
    "    Class                                 object\n",
    "    Flight Distance                        int64\n",
    "    Seat comfort                           int64\n",
    "    Departure/Arrival time convenient      int64\n",
    "    Food and drink                         int64\n",
    "    Gate location                          int64\n",
    "    Inflight wifi service                  int64\n",
    "    Inflight entertainment                 int64\n",
    "    Online support                         int64\n",
    "    Ease of Online booking                 int64\n",
    "    On-board service                       int64\n",
    "    Leg room service                       int64\n",
    "    Baggage handling                       int64\n",
    "    Checkin service                        int64\n",
    "    Cleanliness                            int64\n",
    "    Online boarding                        int64\n",
    "    Departure Delay in Minutes             int64\n",
    "    Arrival Delay in Minutes             float64\n",
    "    dtype: object\n",
    "\n",
    "**Question:** Identify the target (or predicted) variable for passenger\n",
    "satisfaction. What is your initial hypothesis about which variables will\n",
    "be valuable in predicting satisfaction?\n",
    "\n",
    "-   **satisfaction** represents the classification variable to be\n",
    "    predicted.\n",
    "-   Many of these variables seem like meaningful predictors pf\n",
    "    satisfactio. In particular, delays correlated with satisfaction.\n",
    "\n",
    "## Step 2: Model preparation<a href=\"#Step-2:-Model-preparation\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Before you proceed with modeling, consider which metrics you will\n",
    "ultimately want to leverage to evaluate your model.\n",
    "\n",
    "**Question:** Which metrics are most suited to evaluating this type of\n",
    "model?\n",
    "\n",
    "-   As this is a binary classification probelm, it will be important to\n",
    "    evaluate not just accuracy, but the balance of false positives and\n",
    "    false negatives that the model's predictions provide.\n",
    "-   The ROC AUC (Area Under the Receiver Operating Characeterisitc)\n",
    "    score is also suited to this type of modeling.\n",
    "\n",
    "### Prepare your data for predictions<a href=\"#Prepare-your-data-for-predictions\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "You may have noticed when previewing your data that there are several\n",
    "non-numerical variables (`object` data types) within the dataset.\n",
    "\n",
    "To prepare this DataFrame for modeling, first convert these variables\n",
    "into a numerical format.\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    # Convert the object predictor variables to numerical dummies.\n",
    "    airline_data_dummies = pd.get_dummies(airline_data,\n",
    "                                              columns=['satisfaction', 'Customer Type', 'Type of Travel', 'Class'])\n",
    "\n",
    "### Isolate your target and predictor variables<a href=\"#Isolate-your-target-and-predictor-variables\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Separately define the target variable (`satisfaction`) and the features.\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    # Define the y (target) variable.\n",
    "    y = airline_data_dummies['satisfaction_satisfied']\n",
    "\n",
    "    # Define the X (predictor) variables.\n",
    "    X = airline_data_dummies.drop(['satisfaction_satisfied', 'satisfaction_dissatisfied'], axis = 1)\n",
    "\n",
    "### Divide your data<a href=\"#Divide-your-data\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Divide your data into a training set (75% of the data) and test set (25%\n",
    "of the data). This is an important step in the process, as it allows you\n",
    "to reserve a part of the data that the model has not used to test how\n",
    "well the model generalizes (or performs) on new data.\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    # Perform the split operation on your data.\n",
    "    # Assign the outputs as follows: X_train, X_test, y_train, y_test.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "## Step 3: Model building<a href=\"#Step-3:-Model-building\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### \"Instantiate\" your XGBClassifer<a href=\"#%22Instantiate%22-your-XGBClassifer\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Before you fit your model to your airline dataset, first create the XGB\n",
    "Classifier model and define its objective. You'll use this model to fit\n",
    "and score different hyperparameters during the GridSearch\n",
    "cross-validation process.\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    # Define xgb to be your XGBClassifier.\n",
    "    xgb = XGBClassifier(objective='binary:logistic', random_state=0)\n",
    "\n",
    "### Define the parameters for hyperparameter tuning<a href=\"#Define-the-parameters-for-hyperparameter-tuning\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "To identify suitable parameters for your `xgboost` model, first define\n",
    "the parameters for hyperparameter tuning. Specifically, consider tuning\n",
    "`max_depth`, `min_child_weight`, `learning_rate`, `n_estimators`,\n",
    "`subsample`, and/or `colsample_bytree`.\n",
    "\n",
    "Consider a more limited range for each hyperparameter to allow for\n",
    "timely iteration and model training. For example, using a single\n",
    "possible value for each of the six hyperparameters listed above will\n",
    "take approximately one minute to run on this platform.\n",
    "\n",
    "    {\n",
    "        'max_depth': [4],\n",
    "        'min_child_weight': [3],\n",
    "        'learning_rate': [0.1],\n",
    "        'n_estimators': [5],\n",
    "        'subsample': [0.7],\n",
    "        'colsample_bytree': [0.7]\n",
    "    }\n",
    "\n",
    "If you add just one new option, for example by changing `max_depth: [4]`\n",
    "to `max_depth: [3, 6]`, and keep everything else the same, you can\n",
    "expect the run time to approximately double. If you use two\n",
    "possibilities for each hyperparameter, the run time would extend to \\~1\n",
    "hour.\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    # Define parameters for tuning as `cv_params`.\n",
    "    cv_params = {'max_depth': [4, 6],\n",
    "                   'min_child_weight': [3, 5],\n",
    "                   'learning_rate': [0.1, 0.2, 0.3],\n",
    "                   'n_estimators': [5,10,15],\n",
    "                   'subsample': [0.7],\n",
    "                   'colsample_bytree': [0.7]\n",
    "                   }\n",
    "\n",
    "**Question:** What is the likely effect of adding more estimators to\n",
    "your GridSearch?\n",
    "\n",
    "More estimators will initially improve the model's performance. However,\n",
    "increasing the number of estimators will also considerably increase the\n",
    "time spent during the GridSearch process, and there will be diminishing\n",
    "returns as the number of estimators continues to increase.\n",
    "\n",
    "### Define how the models will be evaluated<a href=\"#Define-how-the-models-will-be-evaluated\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Define how the models will be evaluated for hyperparameter tuning. To\n",
    "yield the best understanding of model performance, utilize a suite of\n",
    "metrics.\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    # Define your criteria as `scoring`.\n",
    "    scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "### Construct the GridSearch cross-validation<a href=\"#Construct-the-GridSearch-cross-validation\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Construct the GridSearch cross-validation using the model, parameters,\n",
    "and scoring metrics you defined. Additionally, define the number of\n",
    "folds and specify *which metric* from above will guide the refit\n",
    "strategy.\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    # Construct your GridSearch.\n",
    "    xgb_cv = GridSearchCV(xgb, cv_params, scoring = scoring, cv=5, refit='f1')\n",
    "\n",
    "### Fit the GridSearch model to your training data<a href=\"#Fit-the-GridSearch-model-to-your-training-data\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "If your GridSearch takes too long, revisit the parameter ranges above\n",
    "and consider narrowing the range and reducing the number of estimators.\n",
    "\n",
    "**Note:** The following cell might take several minutes to run.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    %%time\n",
    "    # fit the GridSearch model to training data\n",
    "    xgb_cv = xgb_cv.fit(X_train, y_train)\n",
    "    xgb_cv\n",
    "\n",
    "**Question:** Which optimal set of parameters did the GridSearch yield?\n",
    "\n",
    "Through accessing the **best*params*** attribute of the fitted\n",
    "GridSearch model, the optimal set of hyperparameters was:\n",
    "{'colsample_bytree': 0.7, 'learning_rate': 0.3, 'max_depth': 6,\n",
    "'min_child_weight': 5, 'n_estimators': 15, 'subsample': 0.7}\n",
    "\n",
    "### Save your model for reference using `pickle`<a href=\"#Save-your-model-for-reference-using-pickle\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Use the `pickle` library you've already imported to save the output of\n",
    "this model.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Use `pickle` to save the trained model.\n",
    "    pickle.dump(xbg_cv, open('xgb_cv.sav', 'wb'))\n",
    "\n",
    "## Step 4: Results and evaluation<a href=\"#Step-4:-Results-and-evaluation\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Formulate predictions on your test set<a href=\"#Formulate-predictions-on-your-test-set\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "To evaluate the predictions yielded from your model, leverage a series\n",
    "of metrics and evaluation techniques from scikit-learn by examining the\n",
    "actual observed values in the test set relative to your model's\n",
    "prediction.\n",
    "\n",
    "First, use your trained model to formulate predictions on your test set.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Apply your model to predict on your test data. Call this output \"y_pred\".\n",
    "    y_pred = xgb_cv.predict(X_test)\n",
    "\n",
    "### Leverage metrics to evaluate your model's performance<a href=\"#Leverage-metrics-to-evaluate-your-model&#39;s-performance\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Apply a series of metrics from scikit-learn to assess your model.\n",
    "Specifically, print the accuracy score, precision score, recall score,\n",
    "and f1 score associated with your test data and predicted values.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # 1. Print your accuracy score.\n",
    "    ac_score = metrics.accuracy_score(y_test, y_pred)\n",
    "    print('accuracy score:', ac_score)\n",
    "\n",
    "    # 2. Print your precision score.\n",
    "    pc_score = metrics.precision_score(y_test, y_pred)\n",
    "    print('precision score:', pc_score)\n",
    "\n",
    "    # 3. Print your recall score.\n",
    "    rc_score = metrics.recall_score(y_test, y_pred)\n",
    "    print('recall score:', rc_score)\n",
    "\n",
    "    # 4. Print your f1 score.\n",
    "    f1_score = metrics.f1_score(y_test, y_pred)\n",
    "    print('f1 score:', f1_score)\n",
    "\n",
    "**Question:** How should you interpret your accuracy score?\n",
    "\n",
    "The accuracy score for this model is 0.939, or 93.9% accurate.\n",
    "\n",
    "**Question:** Is your accuracy score alone sufficient to evaluate your\n",
    "model?\n",
    "\n",
    "In classification problems, accuracy is useful to know but may not be\n",
    "the best metric to evaluate this model.\n",
    "\n",
    "**Question:** When observing the precision and recall scores of your\n",
    "model, how do you interpret these values, and is one more accurate than\n",
    "the other?\n",
    "\n",
    "Precision and recall scores are both useful to evaluate the correct\n",
    "predictive capability of the model because they balance the false\n",
    "positives and false negatives inherent in prediction. The model shows a\n",
    "precision score of 0.948, suggesting the model is very good at\n",
    "predicting true positives. This means the model correctly predicts\n",
    "whether the airline passenger will be satisfied. The recall score of\n",
    "0.940 is also very good. This means that the model does a good job of\n",
    "correctly identifying dissatisfied passengers within the dataset. These\n",
    "two metrics combined give a better assessment of model performance than\n",
    "the accuracy metric does alone.\n",
    "\n",
    "**Question:** What does your model's F1 score tell you, beyond what the\n",
    "other metrics provide?\\*\n",
    "\n",
    "The F1 score balances the precision and recall performance to give a\n",
    "combined assessment of how well this model delivers predictions. The F1\n",
    "score is 0.944, which suggests very strong predictive power in this\n",
    "model.\n",
    "\n",
    "### Gain clarity with the confusion matrix<a href=\"#Gain-clarity-with-the-confusion-matrix\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "Recall that a **confusion matrix** is a graphic that shows a model's\n",
    "true and false positives and true and false negatives. It helps to\n",
    "create a visual representation of the components feeding into the\n",
    "metrics above.\n",
    "\n",
    "Create a confusion matrix based on your predicted values for the test\n",
    "set.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Construct and display your confusion matrix.\n",
    "\n",
    "    # Construct the confusion matrix for your predicted and test values.\n",
    "    cm = metrics.confusion_matrix(y_tes, y_pred)\n",
    "\n",
    "    # Create the display for your confusion matrix.\n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=xgb_cv.classes_)\n",
    "\n",
    "    # Plot the visual in-line.\n",
    "    disp.plot()\n",
    "\n",
    "**Question:** When observing your confusion matrix, what do you notice?\n",
    "Does this correlate to any of your other calculations?\n",
    "\n",
    "The top left to bottom right diagonal in the confusion matrix represents\n",
    "the correct predictions, and the ratio of these squares showcases the\n",
    "accuracy.\n",
    "\n",
    "The concentration of true positives and trie negatives stands out\n",
    "relative to false positives and false negatives, respectively. This\n",
    "ratio is why the precision score is so high 0.944.\n",
    "\n",
    "### Visualize most important features<a href=\"#Visualize-most-important-features\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "`xgboost` has a built-in function to visualize the relative importance\n",
    "of the features in the model using `matplotlib`. Output and examine the\n",
    "feature importance of your model.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Plot the relative feature importance of the predictor variables in your model.\n",
    "    plot_importance(xgb_cv.best_estimator_)\n",
    "\n",
    "**Question:** Examine the feature importances outputted above. What is\n",
    "your assessment of the result? Did anything surprise you?\n",
    "\n",
    "-   By a wide margin, **seat comfort** rated as most important in the\n",
    "    model. The type of seating is very different between first class and\n",
    "    coach seating. However, the perks of being in first class also go\n",
    "    beyond the seating type. Perhaps that is an underlying explanation\n",
    "    of this feature#s importance.\n",
    "-   Surprisingly, delays did not score as highly important.\n",
    "\n",
    "### Compare models<a href=\"#Compare-models\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Create a table of results to compare model performance.\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "    # Create a table of results to compare model performance.\n",
    "    table = pd.DataFrame({'Model': [\"Tuned Decision Tree\", \"Tuned Random Forest\", \"Tuned XGBoost\"],\n",
    "                          'F1': [0.945422, 0.947306, f1_score],\n",
    "                          'Recall': [0.935863, 0.944501, rc_score],\n",
    "                          'Precision': [0.955197, 0.950128, pc_score],\n",
    "                          'Accuracy': [0.940864, 0.942450, ac_score]\n",
    "                         }\n",
    "                        )\n",
    "    table\n",
    "\n",
    "**Question:** How does this model compare to the decision tree and\n",
    "random forest models you built in previous labs?\n",
    "\n",
    "Based on the results shown in the table above, the F1, precision,\n",
    "recall, and accuracy scores of the XGBoost model are similar to the\n",
    "corresponding scores of the decision tree and random forest models. The\n",
    "random forest model seemed to outperform the decision tree model as well\n",
    "as the XGBoost model.\n",
    "\n",
    "## Considerations<a href=\"#Considerations\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "**What are some key takeaways you learned from this lab?**\n",
    "\n",
    "-   The evaluation of the model is important to inform if the model has\n",
    "    delivered accurate predictions.\n",
    "-   Splitting the data is important for ensuring that there is new data\n",
    "    for the model to test its predictive performance.\n",
    "-   Each metric provides an evaluation from a different standpoint, and\n",
    "    accuracy alone is not a strong way to evaluate a model.\n",
    "-   Effective assessments balance the true/false positives versus\n",
    "    true/false negatives through the confusion matrix and F1 score.\n",
    "\n",
    "**How would you share your findings with your team?**\n",
    "\n",
    "-   Showcase the data used to create the prediction and the performance\n",
    "    of the model overall.\n",
    "-   Review the sample output of the features and the confusion matrix to\n",
    "    reference the model's performance.\n",
    "-   Highlight the metric values, emphasizing the F1 score.\n",
    "-   Visualize the feature importance to showcase what drove the model's\n",
    "    predictions.\n",
    "\n",
    "**What would you share with and recommend to stakeholders?**\n",
    "\n",
    "-   The model created is highly effective at predicting passenger\n",
    "    satisfaction.\n",
    "-   The feature importance of seat comfort warrants additional\n",
    "    investigation. It will be important to ask domain experts why they\n",
    "    believe this feature scores so highly in this model.\n",
    "\n",
    "**Congratulations!** You've completed this lab. However, you may not\n",
    "notice a green check mark next to this item on Coursera's platform.\n",
    "Please continue your progress regardless of the check mark. Just click\n",
    "on the \"save\" icon at the top of this notebook to ensure your work has\n",
    "been logged"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
